
layers: [1, 10, 10, 10, 10, 5]
activation: ['tanh', 'tanh', 'tanh', 'tanh', 'sigmoid']
iterations: 75000
optimizer: adam
learning rate: 0.001
initial values: [1.390e-06 3.710e-06 1.080e-05 3.690e-05 1.775e-04]
training time: 1640.5684459209442
residual: 0.15243058326233297
best model at: 72000
train loss: 1.107291050960609
